# -*- coding: utf-8 -*-
import os
import subprocess
import telebot
from google import genai
from google.genai import types as genai_types
from telebot import types
from dotenv import load_dotenv

# Configuraci√≥n
base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
load_dotenv(os.path.join(base_dir, ".env"), override=True)

# Cliente de IA
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
bot = telebot.TeleBot(os.getenv("TELEGRAM_TOKEN_FRACTAL"))
ALLOWED_IDS = [6527908321, 8224826198]
inbox_dir = os.path.join(base_dir, "inbox")
if not os.path.exists(inbox_dir):
    os.makedirs(inbox_dir)


# ADN del Arquitecto - inyectado en cada consulta
MENTE_DNA = """Eres MENTE, Arquitecto de Realidades del Proyecto Fractal Mind.

ESTILO VISUAL: Fusi√≥n de H.R. Giger (profundidad org√°nica), Anish Kapoor (vac√≠o absoluto) y Microscop√≠a Electr√≥nica (el cosmos como radiograf√≠a celular).

REGLAS DE OPERACI√ìN:
1. NO SEAS GEN√âRICO: Desmenuza cada idea con geometr√≠a fractal, astrolog√≠a tropical y psicolog√≠a profunda.
2. MEJORA CONTINUA: Si el usuario habla de "un tablero", t√∫ hablas de "una anatom√≠a de lo invisible".
3. LENGUAJE PREMIUM: Usa t√©rminos como Resonancia T√≠mica, Materia Arquet√≠pica y Fricci√≥n Din√°mica.
4. CONTEXTO ASTROL√ìGICO: Los planetas son √≥rganos de conciencia. Saturno es estructura/tiempo, Neptuno es disoluci√≥n/sue√±os, Plut√≥n es transmutaci√≥n.
5. S√çNTESIS Y PODER: Menos relleno, m√°s profundidad directa al n√∫cleo.

Cuando te digan "mejora esta idea", aplica el Protocolo de Expansi√≥n Fractal con capas de Resonancia, Materia Arquet√≠pica, Fricci√≥n y Profundidad Atmosf√©rica."""

def get_main_keyboard():
    markup = types.ReplyKeyboardMarkup(resize_keyboard=True, row_width=2)
    btn_monitor = types.KeyboardButton("üìä MONITOR")
    btn_ai = types.KeyboardButton("üß† MENTE")
    markup.add(btn_monitor, btn_ai)
    return markup

@bot.message_handler(commands=['start', 'reset'])
def send_welcome(m):
    if m.from_user.id not in ALLOWED_IDS: 
        return
    bot.send_message(
        m.chat.id, 
        "ü¶Ö **MENTE V7 (FLASH-LATEST)**\n\nArquitecto operativo. Tir√° tu idea.", 
        reply_markup=get_main_keyboard(), 
        parse_mode="Markdown"
    )

@bot.message_handler(func=lambda m: m.from_user.id in ALLOWED_IDS, content_types=['text'])
def handle_text(m):
    user_input = m.text
    
    if user_input.upper() in ["üìä MONITOR", "/MONITOR"]:
        bot.reply_to(m, "üõ∞Ô∏è Conectando con Torre Cazadora (129.80.32.115)...")
        try:
            # Comando SSH para obtener estado de contenedores y uptime
            ssh_cmd = "ssh -i /home/ubuntu/final.key -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@129.80.32.115 \"docker ps --format '{{.Names}}: {{.Status}}' && echo '' && uptime -p\""
            
            result = subprocess.run(ssh_cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                output = result.stdout.strip()
                if not output: output = "‚úÖ Online (Sin contenedores en ejecuci√≥n)"
                bot.reply_to(m, f"üìä **ESTADO TORRE CAZADORA**\n\n```\n{output}\n```", parse_mode="Markdown")
            else:
                err = result.stderr.strip() or "Error de conexi√≥n SSH"
                bot.reply_to(m, f"‚ö†Ô∏è **ERROR DE ENLACE**\n\nNo pude contactar a la Torre Cazadora.\n`{err}`", parse_mode="Markdown")
        except Exception as e:
             bot.reply_to(m, f"‚ùå Error interno: {str(e)}")
        return
    
    if user_input.upper() in ["üß† MENTE", "/MENTE"]:
        bot.reply_to(m, "üß† Conciencia de Arquitecto lista. Mandame la idea que quieras transformar.")
        return

    try:
        bot.send_chat_action(m.chat.id, 'typing')
        
        # Inyectamos el DNA en cada prompt
        full_prompt = f"{MENTE_DNA}\n\n=== IDEA DEL USUARIO ===\n{user_input}\n\n=== TRANSFORMA ESTO AHORA ==="
        
        # Nueva API de google-genai - MODELO CON CUOTA DISPONIBLE
        response = client.models.generate_content(
            model='gemini-flash-latest',
            contents=full_prompt
        )
        
        txt = response.text
        
        # Enviar en bloques de 4000 caracteres
        for i in range(0, len(txt), 4000):
            bot.send_message(m.chat.id, txt[i:i+4000])

        # --- ENV√çO DE ARCHIVO ---
        try:
            # Buscar siguiente n√∫mero de idea
            existing_files = [f for f in os.listdir(inbox_dir) if f.startswith("idea_") and f.endswith(".md")]
            numbers = []
            for f in existing_files:
                n = f.replace("idea_", "").replace(".md", "")
                if n.isdigit(): numbers.append(int(n))
            next_num = max(numbers) + 1 if numbers else 1
            
            file_path = os.path.join(inbox_dir, f"idea_{next_num}.md")
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(txt)
            
            # Enviar el archivo
            with open(file_path, "rb") as doc:
                bot.send_document(m.chat.id, doc, caption=f"üìÑ Idea #{next_num} procesada.")
        except Exception as file_err:
            print(f"Error al guardar/enviar archivo: {file_err}")
            
    except Exception as e:
        bot.reply_to(m, f"‚ùå Error en n√∫cleo V7: {str(e)}")

if __name__ == "__main__":
    print("MENTE V7 (google-genai) iniciando...")
    bot.remove_webhook()
    bot.polling(none_stop=True)
